// "hello world"
wf := import("@platforma-sdk/workflow-tengo:workflow")
ll := import("@platforma-sdk/workflow-tengo:ll")
exec := import("@platforma-sdk/workflow-tengo:exec")
assets:= import("@platforma-sdk/workflow-tengo:assets")
xsv := import("@platforma-sdk/workflow-tengo:pframes.xsv")
pframes := import("@platforma-sdk/workflow-tengo:pframes")
maps := import("@platforma-sdk/workflow-tengo:maps")
pSpec := import("@platforma-sdk/workflow-tengo:pframes.spec")
text := import("text")
slices := import("@platforma-sdk/workflow-tengo:slices")
json := import("json")

prepareFastaSw := assets.importSoftware("@platforma-open/milaboratories.clonotype-clustering.software:prepare-fasta")
processResultsSw := assets.importSoftware("@platforma-open/milaboratories.clonotype-clustering.software:process-results")
mmseqsSw := assets.importSoftware("@platforma-open/soedinglab.software-mmseqs2:main")

setTableProps := func(spec, label, visibility, orderPriority) {
	return maps.deepMerge(spec, {
		annotations: {
			"pl7.app/label": label,
			"pl7.app/table/visibility": visibility ? "default" : "optional",
			"pl7.app/table/orderPriority": orderPriority
		}
	})
}

wf.prepare(func(args) {
	bundleBuilder := wf.createPBundleBuilder()
	bundleBuilder.ignoreMissingDomains() // to make query work for both bulk and single cell data
	bundleBuilder.addAnchor("main", args.datasetRef)

	// abundance
	bundleBuilder.addSingle({
		axes: [ { anchor: "main", idx: 0 }, { anchor: "main", idx: 1 }],
		annotations: {
				"pl7.app/isAbundance": "true",
				"pl7.app/abundance/normalized": "false",
				"pl7.app/abundance/isPrimary": "true"
			}
		},
		"abundance")

	for ref in args.sequencesRef {
		// pull sequences
		bundleBuilder.addSingle(ref)
	}

	// @TODO: Implement in the future
	// // pull genes
	// for gene in ["V", "J"] {
	// 	bundleBuilder.addSingle({
	// 			axes: [{ anchor: "main", idx: 1 }],
	// 			name: "pl7.app/vdj/geneHit",
	// 			domain: {
	// 				"pl7.app/vdj/reference": gene + "Gene",
	// 				"pl7.app/vdj/scClonotypeChain": "A",
	// 				"pl7.app/vdj/scClonotypeChain/index": "primary"
	// 			}
	// 		},
	// 	 gene + "Gene")
	// }

	// mmseqs2 uses same sequence for centroids, so we use same clonotypeKey as a clusterId
	// and we need to pull corresponding labels from the result pool
	// @TODO: remove this part when this labels are generated in bulk MiXCR workflow
	bundleBuilder.addMulti(
		{
			axes: [{ anchor: "main", idx: 1 }],
			name: "pl7.app/label"
		}, "clonotypeKeyLabels")

	return {
		columns: bundleBuilder.build()
		}
})

wf.body(func(args) {
	blockId := wf.blockId().getDataAsJson()

	// sort to preserve order of sequences
	sequencesRef := slices.quickSort(args.sequencesRef)

	columns := args.columns
	datasetSpec := columns.getSpec(args.datasetRef)
	abundanceSpec := columns.getSpec("abundance")

	// sType := args.sequenceType == "aminoacid" ? "aa" : "nt"

	isSingleCell := datasetSpec.axesSpec[1].name == "pl7.app/vdj/scClonotypeKey"


	/***** Step 1: do clustering on the clonotype level *****/

	// input table
	seqTableBuilder := pframes.tsvFileBuilder()
	seqTableBuilder.mem("32GiB") // @TODO: set based on the size of the input
	seqTableBuilder.cpu(4) // @TODO: set based on the size of the input
	
	seqTableBuilder.setAxisHeader(datasetSpec.axesSpec[1].name, "clonotypeKey")
	for nr, seq in sequencesRef {
		seqTableBuilder.add(columns.getColumn(seq), {header: "sequence_" + string(nr)})
	}
	seqTable := seqTableBuilder.build()

	// prepare fasta file
	fasta := exec.builder().
		software(prepareFastaSw).
		mem("16GiB").
		cpu(1).
		addFile("input.tsv", seqTable).
		saveFile("output.fasta").
		run()

	// get split memory limit based on real system ram
	memLimit := "{int(ceil(system.ram.gb * 0.8))}" + "G"

	mem := "32GiB" // @TODO: set based on the size of the input
	cpu := 16

	if !is_undefined(args.mem) {
		mem = string(args.mem) + "GiB"
		memLimit = string(int(args.mem * 0.8)) + "G"
	}
	if !is_undefined(args.cpu) {
		cpu = args.cpu
	}

	// run mmseqs2
	// NOTE: mmseqs2 produces different results for same input (different line order),
	// so we save the result in the output to prevent CID conflict by deduplication
	mmseqs := exec.builder().
		software(mmseqsSw).
		mem(mem).
		cpu(cpu).
		dontSaveStdoutOrStderr(). // important to avoid CID conflict problems coming from different stdout output on same datasets
		arg("easy-cluster").
		arg("input.fasta").
		arg("result").
		arg("tmp").
		arg("--split-memory-limit").argWithVar(memLimit).
		arg("--min-seq-id").arg(string(args.identity)).
		arg("-c").arg(string(args.coverageThreshold)).
		arg("--cov-mode").arg(string(args.coverageMode)).
		//  --similarity-type INT            Type of score used for clustering. 1: alignment score 2: sequence identity [2]
		arg("--similarity-type").arg(args.similarityType == "sequence-identity" ? "2" : "1").
		addFile("input.fasta", fasta.getFile("output.fasta")).
		saveFile("result_cluster.tsv").
		run()

	clusters := mmseqs.getFile("result_cluster.tsv")

	/******* Step 2: aggregate all data and generate results *******/
	cloneTableBuilder := pframes.tsvFileBuilder()
	cloneTableBuilder.add(columns.getColumn("abundance"), {header: "abundance"})

	for nr, seq in sequencesRef {
		cloneTableBuilder.add(columns.getColumn(seq), {header: "sequence_" + string(nr)})
	}

	// Get the array of label columns using the correct method
	clonotypeKeyLabelsArray := columns.getColumns("clonotypeKeyLabels")

	// Check if we have any label columns and use the first one
	if len(clonotypeKeyLabelsArray) > 0 {
		cloneTableBuilder.add(clonotypeKeyLabelsArray[0], {header: "clonotypeKeyLabel"})
	} else {
		// Handle case where no label columns found
		ll.panic("No clonotype key label columns found")
	}

	cloneTableBuilder.setAxisHeader(abundanceSpec.axesSpec[0].name, "sampleId")
	cloneTableBuilder.setAxisHeader(abundanceSpec.axesSpec[1].name, "clonotypeKey")
	cloneTableBuilder.mem("32GiB") // @TODO: set based on the size of the input
	cloneTableBuilder.cpu(4) // @TODO: set based on the size of the input
	cloneTable := cloneTableBuilder.build()


	result := exec.builder().
		software(processResultsSw).
		mem("32GiB"). // @TODO: set based on the size of the input
		cpu(8). // @TODO: set based on the size of the input
		addFile("clusters.tsv", clusters).
		addFile("cloneTable.tsv", cloneTable).
		saveFile("abundances.tsv").
		saveFile("cluster-to-seq.tsv").
		saveFile("clone-to-cluster.tsv").
		saveFile("abundances-per-cluster.tsv"). // cluster to summed abundances
		saveFile("distance_to_centroid.tsv"). // normalized levenshtein distance to centroid
		run()


	abundances := result.getFile("abundances.tsv")
	clusterIdAxisSpec := {
		name: "pl7.app/vdj/clusterId",
		type: "String",
		domain: maps.deepMerge(datasetSpec.axesSpec[1].domain,
		{
			"pl7.app/vdj/clustering/algorithm": "mmseqs2",
			"pl7.app/vdj/clustering/blockId": blockId
			// @TODO: add clustering parameters here
		}),
		annotations: {
			"pl7.app/label": "Cluster Id",
			"pl7.app/table/visibility": "default",
			"pl7.app/table/orderPriority": "990000"
		}
	}

	ac := {
		name: abundanceSpec.name,
		valueType: abundanceSpec.valueType,
		domain: abundanceSpec.domain,
		annotations: abundanceSpec.annotations
	}

	abundanceLabel := abundanceSpec.annotations["pl7.app/label"]

	defaultConvMem := "16GiB" // @TODO: set based on the size of the inputÂ§
	defaultConvCpu := 1 // @TODO: set based on the size of the input

	abundancesPf := xsv.importFile(abundances, "tsv", {
		axes: [{
			column: "sampleId",
			spec: abundanceSpec.axesSpec[0]
		}, {
			column: "clusterId",
			spec: clusterIdAxisSpec
		}],
		columns: [{
			column: "abundance",
			spec: setTableProps(ac, abundanceLabel + " in cluster", false, undefined)
		},
		{
			column: "abundance_normalized",
			spec: setTableProps(maps.deepMerge(ac, {
				valueType: "Float",
				annotations: {
					"pl7.app/abundance/normalized": "true"
				}
			}), text.re_replace("Number", abundanceLabel, "Fraction") + " in cluster", false, undefined)
		}]
	}, {splitDataAndSpec: true, cpu: defaultConvCpu, mem: defaultConvMem})


	abundancesPerCluster := result.getFile("abundances-per-cluster.tsv")

	abundancesPerClusterPf := xsv.importFile(abundancesPerCluster, "tsv", {
		axes: [{
			column: "clusterId",
			spec: clusterIdAxisSpec
		}],
		columns: [{
			column: "abundance_per_cluster",
			spec: setTableProps(ac, "Total " + abundanceLabel + " in cluster", false, undefined)
		}]
	}, {splitDataAndSpec: true, cpu: defaultConvCpu, mem: defaultConvMem})

	cloneToCluster := result.getFile("clone-to-cluster.tsv")
	cloneToClusterPf := xsv.importFile(cloneToCluster, "tsv", {
		axes: [{
			column: "clonotypeKey",
			spec: datasetSpec.axesSpec[1]
		}],
		columns: [{
			column: "clusterLabel",
			spec: setTableProps({
				name: "pl7.app/vdj/clusterId",
				valueType: "String",
				domain: clusterIdAxisSpec.domain,
				annotations: clusterIdAxisSpec.annotations
			}, "Cluster Id", false, undefined)
		}]
	}, {splitDataAndSpec: true, cpu: defaultConvCpu, mem: defaultConvMem})

	cloneToClusterLinkPf := xsv.importFile(cloneToCluster, "tsv", {
		axes: [{
			column: "clonotypeKey",
			spec: datasetSpec.axesSpec[1]
		}, {
			column: "clusterId",
			spec: clusterIdAxisSpec
		}],
		columns: [{
			column: "link",
			spec: setTableProps({
				name: "pl7.app/vdj/link",
				valueType: "Int",
				annotations: {
					"pl7.app/isLinkerColumn": "true"
				}
			}, "Clone to cluster link", false, undefined)
		}]
	}, {splitDataAndSpec: true, cpu: 1, mem: "16GiB"})

	clusterToSeq := result.getFile("cluster-to-seq.tsv")

	seqColumns := [
	{
		column: "size",
		spec: {
			name: "pl7.app/vdj/clustering/clusterSize",
			valueType: "Int",
			annotations: {
				"pl7.app/label": "Cluster Size"
			}
		}
	}, {
		column: "clusterLabel",
		spec: {
			name: "pl7.app/label",
			valueType: "String",
			annotations: {
				"pl7.app/label": "Cluster Id"
			}
		}
	}]

	// Add sequence columns
	for nr, seq in sequencesRef {
		spec := maps.clone(columns.getSpec(seq))
		spec.annotations["pl7.app/label"] = "Centroid " + spec.annotations["pl7.app/label"]
		seqColumns = append(seqColumns, {
			column: "sequence_" + string(nr),
			spec: setTableProps({
				name: spec.name,
				valueType: spec.valueType,
				domain: spec.domain,
				annotations: spec.annotations
			}, spec.annotations["pl7.app/label"], true, "10")
		})
	}

	clusterToSeqPf := xsv.importFile(clusterToSeq, "tsv", {
		axes: [{
			column: "clusterId",
			spec: clusterIdAxisSpec
		}],
		columns: seqColumns
	}, {splitDataAndSpec: true, cpu: defaultConvCpu, mem: defaultConvMem})


	distances := result.getFile("distance_to_centroid.tsv")
	distancesPf := xsv.importFile(distances, "tsv", {
		axes: [{
			column: "clonotypeKey",
			spec: datasetSpec.axesSpec[1]
		}],
		columns: [{
			column: "distanceToCentroid",
			spec: setTableProps({
				name: "pl7.app/vdj/distanceToCentroid",
				valueType: "Float",
				annotations: {
					"pl7.app/min": "0",
					"pl7.app/max": "1",
					"pl7.app/rankingOrder": "decreasing",
					"pl7.app/format": ".2f"
				}
			}, "Distance to centroid", false, undefined)
		}]
	}, {splitDataAndSpec: true, cpu: defaultConvCpu, mem: defaultConvMem})

	// building outputs & exports

	// Create informative label with relevant clustering parameters
	// @TODO: Maybe add feature but will be ridicolously long if many features are used
	identityStr := string(args.identity)
	coverageStr := string(args.coverageThreshold)
	similarityTypeStr := args.similarityType == "sequence-identity" ? "Exact Match" : "BLOSUM"
	
	traceLabel := "Clustering (sim:" + similarityTypeStr + ", ident:" + identityStr + ", cov:" + coverageStr + ")"
	
	trace := pSpec.makeTrace(abundanceSpec,
		{
			type: "milaboratories.clonotype-clustering",
		 	importance: 70,
		 	label: traceLabel
		})

	opf := pframes.pFrameBuilder()
	for k, v in clusterToSeqPf {
		if k == "clusterLabel" {
			 // avoid putting label into the outputs as it will be already in exports;
			 // in future should be safe to add once PlAgDataTable bug is fixed
			continue
		}
		opf.add(k, trace.inject(v.spec), v.data)
	}
	opf = opf.build()

	// Generate pFrames with sequences
	msaPf := pframes.pFrameBuilder()
	i := 0
	for pf in [cloneToClusterLinkPf, distancesPf] {
		for k, v in pf {
			msaPf.add(k + string(i), trace.inject(v.spec), v.data) // label, specs, data
			i = i + 1
		}
	}
	msaPf = msaPf.build()


	epf := pframes.pFrameBuilder() 
	i = 0
	for pf in [abundancesPf, cloneToClusterPf, cloneToClusterLinkPf, clusterToSeqPf, abundancesPerClusterPf, distancesPf] {
		for k, v in pf {
			epf.add(k + string(i), trace.inject(v.spec), v.data) // label, specs, data
			i = i + 1
		}
	}
	epf = epf.build()

	clusterAbundanceSpec := trace.inject(abundancesPf["abundance"].spec)

	return {
		outputs: {
			// for table
			clustersPf: pframes.exportFrame(opf),
			// for MSA
			msaPf: pframes.exportFrame(msaPf),
			// pf for plots
			pf: pframes.exportFrame(epf),
			// specs to outputs for visualization purposes
			clusterAbundanceSpec: clusterAbundanceSpec,

			// save mmseqs2 result in the output to enable deduplication of mmseqs2 run
			// NOTE: mmseqs2 produces different results for same input (different line order)
			mmseqs: clusters
		},
		exports: {
			pf: epf
		}
	}
})

